{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bddfae3-6227-461d-8fa3-0343779225b6",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaca4fa-6c25-4d00-895d-ff04fecd6d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79a634b-8abc-44f8-ae55-1bbc265e6444",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d793b07-7ac9-4146-b855-86bf0a7d22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\CombinedALL.csv'\n",
    "#---------------------------------------------\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the 'Time' column\n",
    "data = data.drop(columns=['Time'])\n",
    "\n",
    "data = data[data['SourceISP'] != 'Rogers']\n",
    "\n",
    "# Make 'Adjusted Time' the first column by reordering\n",
    "columns = ['AdjustedTime'] + [col for col in data.columns if col != 'AdjustedTime']\n",
    "data = data[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2472db-a403-4822-90f4-5a7e490a5fc3",
   "metadata": {},
   "source": [
    "# Data Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6d2a13-4b05-47ee-a3f0-91c1f7c60c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ServerIP column to identify server IP from SourceIP or DestinationIP\n",
    "data['ServerIP'] = data['SourceIP']\n",
    "\n",
    "# Map each unique ServerIP to a ServerID\n",
    "unique_servers = data['ServerIP'].unique()\n",
    "server_mapping = {ip: idx for idx, ip in enumerate(unique_servers, start=1)}\n",
    "data['ServerID'] = data['ServerIP'].map(server_mapping)\n",
    "data['ServerID'] -= 1  # Zero-based indexing for classification targets\n",
    "\n",
    "# Convert 'AdjustedTime' to datetime\n",
    "data['AdjustedTime'] = pd.to_datetime(data['AdjustedTime'])\n",
    "start_time = data['AdjustedTime'].min()\n",
    "data['AdjustedTimeSeconds'] = (data['AdjustedTime'] - start_time).dt.total_seconds()\n",
    "\n",
    "# Select features and the target (ServerID)\n",
    "features = data[['DataLength', 'ARTT', 'SourceLongitude', 'SourceLatitude', \n",
    "                 'DestinationLongitude', 'DestinationLatitude']]\n",
    "label = data['ServerID']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d176d753-2f08-461a-96a4-992eedad9ea8",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3de154-8202-415e-98d4-bd7862a7f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.15, random_state=42)\n",
    "\n",
    "print(\"Number of rows in X_train:\", X_train.shape[0])\n",
    "print(\"Number of rows in X_test:\", X_test.shape[0])\n",
    "print(\"Number of rows in y_train:\", len(y_train))\n",
    "print(\"Number of rows in y_test:\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a295269-542c-4c1e-83c3-0c8ebaa846b4",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bbad02-7e85-4020-806e-c8af854ed5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Checking for NaN or infinite values in X_train_scaled:\", np.isnan(X_train_scaled).any(), np.isinf(X_train_scaled).any())\n",
    "print(\"Checking for NaN or infinite values in X_test_scaled:\", np.isnan(X_test_scaled).any(), np.isinf(X_test_scaled).any())\n",
    "print('Input shape:', (X_train_scaled.shape[1],))\n",
    "print('Unique servers:', (len(unique_servers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e88221-ed2c-452f-990f-68f48a2cc3b0",
   "metadata": {},
   "source": [
    "# DNN Model Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44bf0b-bb3e-4aa9-9d7e-14dc938fc001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DNN model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.001), input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(16, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(len(unique_servers), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Add EarlyStopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb82d7a9-04e4-4e32-b8cc-68372424a138",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc12b614-2d92-45cd-9dfb-9e91ef825c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, validation_split=0.176, batch_size=32, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3463ffa1-5d0b-4cd7-9bb7-41b9fbfad0d6",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063064fc-d096-46f4-82f1-13ff72ed9918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(\"Model accuracy on test set:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109f630e-21f0-4bfe-a35d-02c9877feff0",
   "metadata": {},
   "source": [
    "# Predict and decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dfed5d-610d-4156-ad7b-2537aed11692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and map server IDs for visualization\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)  # Map back to ServerIDs\n",
    "y_test_array = y_test.to_numpy()  # Convert y_test to array for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee1f86-3ff3-46b9-9f15-273e215dc94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scale the entire dataset\n",
    "features_scaled = scaler.transform(features)\n",
    "\n",
    "# Predict for the entire dataset\n",
    "y_pred_full = model.predict(features_scaled)\n",
    "y_pred_full_labels = np.argmax(y_pred_full, axis=1)  # Predicted ServerIDs\n",
    "y_true_full = label.to_numpy()  # True ServerIDs\n",
    "\n",
    "# Create a reverse mapping from ServerID back to ISP\n",
    "serverid_to_isp = data.set_index('ServerID')['SourceISP'].to_dict()\n",
    "\n",
    "# Map each unique ISP to a numerical label for the confusion matrix display\n",
    "unique_isps = sorted(data['SourceISP'].unique())\n",
    "isp_to_num = {isp: idx for idx, isp in enumerate(unique_isps, start=1)}\n",
    "num_to_isp = {idx: isp for isp, idx in isp_to_num.items()}\n",
    "\n",
    "# Map y_true_full and y_pred_full_labels to numerical ISP labels using the reverse and ISP mappings\n",
    "y_true_isp_full = [isp_to_num[serverid_to_isp.get(server_id, 'Unknown ISP')] for server_id in y_true_full]\n",
    "y_pred_isp_full = [isp_to_num[serverid_to_isp.get(server_id, 'Unknown ISP')] for server_id in y_pred_full_labels]\n",
    "\n",
    "# Generate the numerical ISP-based confusion matrix\n",
    "isp_labels_num = sorted(isp_to_num.values())  # Get unique numerical ISP labels\n",
    "conf_matrix_full = confusion_matrix(y_true_isp_full, y_pred_isp_full, labels=isp_labels_num)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Plot the confusion matrix without annotations or legend\n",
    "plt.figure(figsize=(8, 6))  # Increased figure size for better readability\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=isp_labels_num)\n",
    "disp.plot(cmap=plt.cm.Blues, ax=plt.gca(), colorbar=False)  # Disable colorbar if not needed\n",
    "\n",
    "# # Remove the text annotations (numbers inside the squares)\n",
    "# for text in plt.gca().texts:\n",
    "#     text.set_visible(False)\n",
    "\n",
    "# Add title and customize the appearance\n",
    "plt.xticks(rotation=45, fontsize=12)  # Rotate x-axis labels for clarity\n",
    "plt.yticks(fontsize=12)  # Adjust y-axis label font size\n",
    "plt.xlabel(\"Assigned Server\", fontsize=14, labelpad=10)\n",
    "plt.ylabel(\"Best Server\", fontsize=14, labelpad=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec7e7b3-ef7b-44ae-a6fc-e5722ee49f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "output_file = r'C:\\Users\\DNNPredictions.csv'\n",
    "results_df = pd.DataFrame({\n",
    "    'True ServerID': y_test_array,\n",
    "    'Predicted ServerID': y_pred_labels\n",
    "})\n",
    "results_df.to_csv(output_file, index=False)\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c09aba-e2b6-4765-8ff5-efb8e92874ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
