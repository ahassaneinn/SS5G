{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bddfae3-6227-461d-8fa3-0343779225b6",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaca4fa-6c25-4d00-895d-ff04fecd6d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79a634b-8abc-44f8-ae55-1bbc265e6444",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d793b07-7ac9-4146-b855-86bf0a7d22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\File.csv'\n",
    "#---------------------------------------------\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Drop rows where 'ISP' is missing to retain only rows with servers\n",
    "data = data.dropna(subset=['Org'])\n",
    "\n",
    "# Make 'Adjusted Time' the first column by reordering\n",
    "columns = ['AdjustedTime'] + [col for col in data.columns if col != 'AdjustedTime']\n",
    "data = data[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2472db-a403-4822-90f4-5a7e490a5fc3",
   "metadata": {},
   "source": [
    "# Data Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6d2a13-4b05-47ee-a3f0-91c1f7c60c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each unique 'Source' IP to a server ID\n",
    "unique_servers = data['Source'].unique()\n",
    "server_mapping = {ip: idx for idx, ip in enumerate(unique_servers, start=1)}\n",
    "data['ServerID'] = data['Source'].map(server_mapping)\n",
    "data['ServerID'] -= 1\n",
    "\n",
    "# Select features and the new target (ServerID)\n",
    "features = data[['AdjustedTime', 'Protocol', 'Connection', 'User', 'Length', 'ARTT', 'Longitude', 'Latitude', 'Org']]\n",
    "label = data['ServerID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a295269-542c-4c1e-83c3-0c8ebaa846b4",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bbad02-7e85-4020-806e-c8af854ed5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Convert datetime to numeric\n",
    "data['AdjustedTime'] = pd.to_datetime(data['AdjustedTime'])\n",
    "data['AdjustedTimestamp'] = data['AdjustedTime'].astype(np.int64) // 10**9\n",
    "\n",
    "# Label encode categorical features\n",
    "for col in ['Protocol', 'Connection', 'User', 'Org']:\n",
    "    data[col] = LabelEncoder().fit_transform(data[col])\n",
    "\n",
    "# Define features\n",
    "features = ['AdjustedTimestamp', 'Protocol', 'Connection', 'User', 'Length', 'ARTT', 'Longitude', 'Latitude', 'Org']\n",
    "X = data[features]\n",
    "y = data['ServerID']\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e88221-ed2c-452f-990f-68f48a2cc3b0",
   "metadata": {},
   "source": [
    "# DNN Model Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44bf0b-bb3e-4aa9-9d7e-14dc938fc001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DNN model with at least 3 layers\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.001), input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(16, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(len(unique_servers), activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Add EarlyStopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',   # Monitor validation loss\n",
    "    patience=10,           # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True # Restore the best model weights after stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb82d7a9-04e4-4e32-b8cc-68372424a138",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc12b614-2d92-45cd-9dfb-9e91ef825c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, validation_split=0.176, batch_size=32, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3463ffa1-5d0b-4cd7-9bb7-41b9fbfad0d6",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063064fc-d096-46f4-82f1-13ff72ed9918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(\"Model accuracy on test set:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
